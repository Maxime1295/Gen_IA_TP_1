{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each practical exercise (TP), please work in groups of two or three. Then, create a private GitHub repository and add me (my GitHub is arthur-75) to your project. Finally, share the link to your project (or TP) under  Practical Exercises and make sure to choose your team name :-)\n",
    "Autoencoders on Fashion MNIST\n",
    "Goal:\n",
    "Load and visualize the Fashion MNIST dataset.\n",
    "Build an Autoencoder using convolutional layers.\n",
    "Train the Autoencoder and evaluate its performance.\n",
    "Extract and visualize latent space embeddings.\n",
    "Reconstruct images and generate new ones.\n",
    "1. Load and Visualize the Dataset\n",
    "1.1: Import Necessary Libraries\n",
    "Before diving into implementation, let's import the required libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What transformations might be useful when working with images?\n",
    "\n",
    "1.2: Prepare the Data\n",
    "Load Fashion MNIST and set train=True for training data and train=False for validation data.\n",
    "Apply padding to increase the image size from 28×28 to 32×32.\n",
    "Convert images to tensors so they can be used in PyTorch.\n",
    "Wrap the dataset in a DataLoader to allow efficient mini-batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing \n",
    "transform = transforms.xxx([\n",
    "  xxx=xxx ,  # Pad 28x28 images to 32x32\n",
    "  xxx=xxx ,    #Convert images to tensors\n",
    "])\n",
    "batch_size = xxx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "train_dataset = datasets.FashionMNIST(root=\"./data\", train= ..., transform=xxx, download=True)\n",
    "train_loader = DataLoader(xxx, xxx, shuffle=xxx)\n",
    "val_dataset = xxx.xxx(xxx, train=xxx, transform=xxx, download=True)\n",
    "val_loader = xxx(xxxx, xxx, shuffle=xxx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1.3: Visualizing Sample Images\n",
    "Extract a batch of images and labels from the training dataset.\n",
    "Display multiple images in a grid.\n",
    "Use matplotlib to plot the grayscale images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
